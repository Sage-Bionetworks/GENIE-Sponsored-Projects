"""
# sponsoredProject PROCESSES
# - ONE TIMELINE FILE
# - CLINICAL FILE
#   OS_MONTHS = death_date_int - date_first_met_int
#   OS_MONTHS_PRIMARY = death_date_int - primary_dx_date_int
#   All dates are converted from days to months (days/30.4)
#   Add headers
#   REMOVE PATIENTS/SAMPLES THAT DON'T HAVE GENIE SAMPLE IDS
#
# USAGE:
# git clone https://github.com/cBioPortal/cbioportal.git
# python runSP.py ERBB2 ../cbioportal/ --staging
"""
import math
import os
import subprocess

import synapseclient
from synapseclient import File
import pandas as pd

from genie import process_functions, create_case_lists


def replace0(x):
    """
    Replace any floats generated by pandas
    """
    x = x.replace(".0\t", "\t")
    x = x.replace(".0\n", "\n")
    return(x)


def extractColumns(mappingDf, fileTypeList, removeList):
    """
    Function to extract the sample, patient and treatment columns

    Args:
        mappingDf: Data element Table
        fileTypeList: List of instruments eg.
                      ['patient_information',
                       'treatment_information_general',
                       'sample_information',
                       'treatment_information_detailed',
                       'diagnosis_information']
        removeList: If there are any elements you want to remove,
                    pass it in as a list.
    """
    info = mappingDf['instrument'].isin(fileTypeList)
    infoCols = mappingDf['genie_field_name'][info]
    infoCols = infoCols[~infoCols.isin(removeList)].tolist()
    infoColsFirst = ['patient_id']
    infoColsFirst.extend(infoCols)
    return(infoColsFirst)


def configureMafRow(rowArray, headers, keepSamples):
    """
    Configure each maf row

    :param rowArray:       A maf row as a vector
    :param headers:        The maf headers as a vector
    :param keepSamples:    Samples to keep in the maf file

    :returns:              Configured maf row as a text to append
    """
    sampleId = str(rowArray[headers.index('Tumor_Sample_Barcode')])
    if pd.Series(sampleId).isin(keepSamples).any():
        fillnas = [
            't_depth', 't_ref_count', 't_alt_count',
            'n_depth', 'n_ref_count', 'n_alt_count']
        for i in fillnas:
            value = rowArray[headers.index(i)]
            rowArray[headers.index(i)] = "" if str(value) == "." else value
        rowArray[headers.index("Validation_Status")] = ''
        newRow = "\t".join(rowArray)
        newRow += "\n"
        newRow = replace0(newRow)
        return(newRow)
    else:
        return(None)


def replacePeriod(x):
    """
    Replace any periods in a string with blank spaces
    """
    return(x.replace(".", ""))


def change_days_to_months(x):
    """
    Function to change date fields to months
    """
    if math.isnan(x):
        return(pd.np.nan)
    else:
        return(math.floor(x/30.4))


class SponsoredProjectRunner:

    _SPONSORED_PROJECT = ''
    # No need to define in class
    _CASE_LIST_PATH = os.path.join(_SPONSORED_PROJECT, 'case_lists')
    _DATA_ELEMENT_SYN_ID = None
    _NUM_COUNTS = None
    _REDCAP_TO_CBIOMAPPING_SYNID = None
    _UNLABELLED_SYN_ID = None
    _LABELLED_SYN_ID = None
    # Storage of not found samples
    _SP_REDCAP_EXPORTS_SYNID = None
    _SP_SYN_ID = None
    _CASE_LIST_MAF_SAMPLES_TEMPLATE = None
    _CASE_LIST_SYN_ID = None
    _GITHUB_REPO = \
        "https://github.com/Sage-Bionetworks/GENIE-Sponsored-Projects"

    def __init__(self, syn, cbioPath, staging=False, export=False):
        assert os.path.exists(cbioPath)
        self.syn = syn
        self.cbioPath = cbioPath
        self.staging = staging
        self.export = export

    def createSpecimenDf(self, clinicalDf):
        """
        Get specimens
        CUSTOM
        """
        pass

    def createMetaDiagnosisDf(self, timelineDf):
        """
        Get meta diagnosis to append to timelineDf
        """
        metaDiagnosisDf = pd.DataFrame()
        # MET DISEASE IS TIMEPOINT 0
        metaDiagnosisDf['PATIENT_ID'] = \
            timelineDf['PATIENT_ID'].drop_duplicates()
        metaDiagnosisDf['START_DATE'] = 0
        metaDiagnosisDf['EVENT_TYPE'] = 'STATUS'
        metaDiagnosisDf['STATUS'] = 'Metastatic Diagnosis'
        metaDiagnosisDf = \
            metaDiagnosisDf[~metaDiagnosisDf['START_DATE'].isnull()]
        return(metaDiagnosisDf)

    def reviseMetadataFiles(self):
        """
        Helper function to download all the metadata files again
        """
        allFiles = self.syn.getChildren(self._SP_SYN_ID)
        for i in allFiles:
            if 'meta' in i['name']:
                self.syn.get(
                    i['id'],
                    downloadLocation=self._SPONSORED_PROJECT,
                    ifcollision="overwrite.local")

    def createGeneMatrixDf(self, clinicalDf, cnaSamples, usedEnt):
        """
        Create gene matrix dataframe
        """
        data_gene_panel = clinicalDf[["SAMPLE_ID", "SEQ_ASSAY_ID"]]
        data_gene_panel = data_gene_panel.rename(
            columns={"SEQ_ASSAY_ID": "mutations"})
        data_gene_panel = data_gene_panel[data_gene_panel['SAMPLE_ID'] != ""]
        data_gene_panel.drop_duplicates("SAMPLE_ID", inplace=True)
        cnaSeqIds = data_gene_panel['mutations'][
            data_gene_panel['SAMPLE_ID'].isin(cnaSamples)].unique()
        data_gene_panel['cna'] = data_gene_panel['mutations']
        data_gene_panel['cna'][~data_gene_panel['cna'].isin(cnaSeqIds)] = "NA"
        data_gene_panel.to_csv(
            "%s/data_gene_matrix.txt" % self._SPONSORED_PROJECT,
            sep="\t", index=False)
        fileEnt = File(
            "%s/data_gene_matrix.txt" % self._SPONSORED_PROJECT,
            parent=self._SP_SYN_ID)
        if not self.staging:
            self.syn.store(
                fileEnt, used=usedEnt.id, executed=self._GITHUB_REPO)

    def configureClinicalDf(self, clinicalDf, redCapToCbioMappingDf):
        """
        Create clinical file from sponsored project mapped dataframe

        Args:
            clinicalDf:  Can be patient or clinical dataframe
            redCapToCbioMappingDf: Synapse Table with the mapping
                                   between redcap and cbioportal
        """

        # Make sure all column names are in the mapping dataframe
        assert clinicalDf.columns.isin(redCapToCbioMappingDf['code']).all()

        clinicalDf.columns = [
            redCapToCbioMappingDf['cbio'][
                redCapToCbioMappingDf['code'] == col].values[0]
            for col in clinicalDf.columns]

        clinicalDf = clinicalDf.drop_duplicates()
        assert sum(clinicalDf['PATIENT_ID'].isnull()) == 0, \
            "Must have no null patient ids"
        # Remove white spaces for PATIENT/SAMPLE ID
        clinicalDf['PATIENT_ID'] = [
            patient.replace(" ", "") for patient in clinicalDf['PATIENT_ID']]
        clinicalDf['PATIENT_ID'] = clinicalDf.apply(
            lambda x: process_functions.checkGenieId(
                x['PATIENT_ID'], x['CENTER']), axis=1)
        if clinicalDf.get("SAMPLE_ID") is not None:
            # This line should not be here
            clinicalDf = clinicalDf[~clinicalDf['SAMPLE_ID'].isnull()]
            assert sum(clinicalDf['SAMPLE_ID'].isnull()) == 0, \
                "Must have no null sample ids"
            clinicalDf['SAMPLE_ID'] = [
                sample.replace(" ", "") for sample in clinicalDf['SAMPLE_ID']]
            clinicalDf['SAMPLE_ID'] = clinicalDf.apply(
                lambda x: process_functions.checkGenieId(
                    x['SAMPLE_ID'], x['CENTER']), axis=1)
        else:
            # ONCOTREE_CODE should not be pulled from the sponsored project
            clinicalDf['OS_MONTHS'] = \
                clinicalDf['DEATH_DATE_INT'] - clinicalDf['MET_DX_DATE_INT']

        clinicalDf['SP'] = self._SPONSORED_PROJECT

        if clinicalDf.get("OS_STATUS") is not None:
            clinicalDf['OS_STATUS'][
                clinicalDf['OS_STATUS'] == "Dead"] = "DECEASED"
            clinicalDf['OS_STATUS'][
                clinicalDf['OS_STATUS'] == "Alive"] = "LIVING"

        for col in clinicalDf:
            numMissing = sum(clinicalDf[col].isnull())
            if numMissing > 0:
                print("Number of missing %s: %d" % (col, numMissing))

        # Modifying vital status -> os status for some reason
        # (Need to figure out why)

        return(clinicalDf)

    def writeClinicalFile(self, clinicalDf, redCapToCbioMappingDf, sampleType):
        """
        Write out the clinical file

        params:
            clinicalDf: Can be patient or sample clinical dataframe
            redCapToCbioMappingDf: mapping dataframe between redcap
                                   and cbioportal
            sampleType: "patient" or "sample"
        """
        assert sampleType in ["patient", "sample"], \
            "sample type must be patient or sample"
        labels = [
            str(redCapToCbioMappingDf['labels'][
                redCapToCbioMappingDf['cbio'] == col].values[0])
            for col in clinicalDf]
        descriptions = [
            str(redCapToCbioMappingDf['description'][
                redCapToCbioMappingDf['cbio'] == col].values[0])
            for col in clinicalDf]
        colType = [
            str(redCapToCbioMappingDf['colType'][
                redCapToCbioMappingDf['cbio'] == col].values[0])
            for col in clinicalDf]

        clin_path = "{}/data_clinical_{}.txt".format(
            self._SPONSORED_PROJECT, sampleType)
        with open(clin_path, "w+") as clinFile:
            clinFile.write("#%s\n" % "\t".join(labels))
            clinFile.write("#%s\n" % "\t".join(descriptions))
            clinFile.write("#%s\n" % "\t".join(colType))
            clinFile.write("#%s\n" % "\t".join(['1']*len(labels)))
            clinFile.write(replace0(clinicalDf.to_csv(index=False, sep="\t")))
        return(clin_path)

    def run(self):
        """
        This function runs the redcap export to export all files
        """
        if not os.path.exists(self._SPONSORED_PROJECT):
            os.mkdir(self._SPONSORED_PROJECT)
        else:
            filelists = os.listdir(self._SPONSORED_PROJECT)
            for file in filelists:
                if file != "case_lists":
                    os.remove(os.path.join(self._SPONSORED_PROJECT, file))
        # Create full mapping table to get the values of the data model
        mapping = self.syn.tableQuery(
            "select genie_field_name,instrument from {} where "
            "{} is true and phi is false".format(
                self._DATA_ELEMENT_SYN_ID, self._SPONSORED_PROJECT.lower()))
        mappingDf = mapping.asDataFrame()
        newMappingDf = pd.DataFrame()
        for field, instrument in zip(mappingDf.genie_field_name,
                                     mappingDf.instrument):
            # Do not want to append the # values
            if "#" in field:
                # find fields with # and replace with however many times
                # it should loop through
                newfields = [
                    field.replace("#", str(count))
                    for count in list(range(1, self._NUM_COUNTS+1))]
                newDataFrame = pd.DataFrame({
                    "genie_field_name": newfields,
                    "instrument": [instrument]*len(newfields)})
            else:
                newDataFrame = pd.DataFrame({
                    "genie_field_name": field,
                    "instrument": instrument}, index=[0])
            newMappingDf = newMappingDf.append(newDataFrame, sort=False)

        # If there are ever missing fields, they must be added in
        # or else the script will fail
        # missingFields= ['her_status_sample','sample_seq_yn']
        # missingFieldType = ['sample_information']*2
        # newMappingDf = newMappingDf.append(pd.DataFrame({
        #     "genie_field_name": missingFields,
        #     "instrument": missingFieldType}))

        # Extract patient/sample/treatment columns
        patientCols = extractColumns(
            newMappingDf,
            ["patient_information", "treatment_information_general",
             "diagnosis_information"],
            ['errors_patient_info_yn', 'patient_info_errors',
             'errors_dx_info_yn', 'dx_info_errors', 'so_yn'])
        sampleCols = extractColumns(
            newMappingDf, ["sample_information"],
            ["test_sample", "fgfr4_variant", "errors_sample_info_yn",
             "sample_info_errors"])
        treatmentCols = extractColumns(
            newMappingDf, ["treatment_information_detailed"], [])

        unlabelledEnt = self.syn.get(self._UNLABELLED_SYN_ID)
        labelledEnt = self.syn.get(self._LABELLED_SYN_ID)
        unlabeledDf = pd.read_csv(unlabelledEnt.path)
        labeledDf = pd.read_csv(labelledEnt.path)
        # Add on CENTER column for all three file formats
        patientCols.append("redcap_data_access_group")
        sampleCols.append("redcap_data_access_group")
        treatmentCols.append("redcap_data_access_group")

        labeledDf.columns = unlabeledDf.columns
        labeledDf['redcap_data_access_group'][
            labeledDf['redcap_data_access_group'] == "hop"] = "JHU"
        labeledDf['redcap_data_access_group'] = \
            labeledDf['redcap_data_access_group'].apply(lambda x: x.upper())

        patientDf = labeledDf[patientCols]
        patientRows = labeledDf.redcap_repeat_instrument.isnull()
        patientDf = patientDf[patientRows]

        sampleDf = labeledDf[sampleCols]
        sampleRows = labeledDf.redcap_repeat_instrument == "Sample Information"
        sampleDf = sampleDf[sampleRows]
        # Red cap header to cbio header Table mapping
        redCapToCbioMapping = self.syn.tableQuery(
            "SELECT * FROM %s" % self._REDCAP_TO_CBIOMAPPING_SYNID)
        redCapToCbioMappingDf = redCapToCbioMapping.asDataFrame()

        # Get all the samples/patients that should be uploaded to SP projects
        # Hard coded clinical database
        genie_clinicalDb = self.syn.tableQuery(
            'select SAMPLE_ID, PATIENT_ID, ONCOTREE_CODE, SEQ_ASSAY_ID '
            'from syn7517674')
        genie_clinicalDf = genie_clinicalDb.asDataFrame()
        # Hard coded clinicalSP database
        # nonGenie_clinicalDb = self.syn.tableQuery(
        #     'SELECT * FROM syn11492579')
        # nonGenie_clinicalDf = nonGenie_clinicalDb.asDataFrame()
        # genie_clinicalDf = genie_clinicalDf.append(nonGenie_clinicalDf)

        # Only patients and samples that exist in the
        # sponsored project uploads are going to be pulled into the SP project
        finalPatientDf = self.configureClinicalDf(
            patientDf, redCapToCbioMappingDf)
        patient_date_col = [col for col in finalPatientDf.columns
                            if col.endswith("INT")]
        patient_date_col.append("OS_MONTHS")
        final_patientdf_datesdays = finalPatientDf.copy()
        finalPatientDf[patient_date_col] = \
            finalPatientDf[patient_date_col].applymap(change_days_to_months)
        subsetPatientDf = finalPatientDf[
            finalPatientDf['PATIENT_ID'].isin(genie_clinicalDf['PATIENT_ID'])]
        del subsetPatientDf['SP']
        # Remove CENTER and ONCOTREE_CODE from patient because you
        # cannot have these columns in both sample and patient Df,
        # it will fail validation for cbioportal
        del subsetPatientDf['CENTER']
        del subsetPatientDf['ONCOTREE_CODE']

        patientPath = self.writeClinicalFile(
            subsetPatientDf, redCapToCbioMappingDf, "patient")

        finalSampleDf = self.configureClinicalDf(
            sampleDf, redCapToCbioMappingDf)

        sample_date_cols = ['SAMPLE_DATE_INT', 'AGE_AT_SEQ_REPORT']
        final_sampledf_datesdays = finalSampleDf.copy()
        finalSampleDf[sample_date_cols] = \
            finalSampleDf[sample_date_cols].applymap(change_days_to_months)
        # Fill in ONCOTREE_CODE
        finalSampleDf['ONCOTREE_CODE'] = [
            genie_clinicalDf['ONCOTREE_CODE'][
                genie_clinicalDf['SAMPLE_ID'] == sample].values[0]
            if sum(genie_clinicalDf['SAMPLE_ID'] == sample) > 0
            else float('nan') for sample in finalSampleDf['SAMPLE_ID']]
        # Fill in SEQ_ASSAY_ID
        finalSampleDf['SEQ_ASSAY_ID'] = [
            genie_clinicalDf['SEQ_ASSAY_ID'][
                genie_clinicalDf['SAMPLE_ID'] == sample].values[0]
            if sum(genie_clinicalDf['SAMPLE_ID'] == sample) > 0
            else float('nan') for sample in finalSampleDf['SAMPLE_ID']]

        subsetSampleDf = finalSampleDf[
            finalSampleDf['SAMPLE_ID'].isin(genie_clinicalDf['SAMPLE_ID'])]
        del subsetSampleDf['SP']

        samplePath = self.writeClinicalFile(
            subsetSampleDf, redCapToCbioMappingDf, "sample")

        # Remove oncotree code here, because no longer need it
        mergedClinicalDf = subsetSampleDf.merge(
            subsetPatientDf, on="PATIENT_ID", how="outer")

        if mergedClinicalDf.get("SAMPLE_ID") is not None:
            print("Samples not in GENIE clinical databases (SP and normal)")
            notFoundSamples = mergedClinicalDf[
                'SAMPLE_ID'][~mergedClinicalDf['SAMPLE_ID'].isin(
                    genie_clinicalDf['SAMPLE_ID'])]
            if not notFoundSamples.empty:
                print(notFoundSamples[~notFoundSamples.isnull()])
                notFoundSamples.to_csv("notfoundsamples.csv", header=False)
                if not self.staging:
                    self.syn.store(
                        synapseclient.File(
                            "notfoundsamples.csv",
                            parent=self._SP_REDCAP_EXPORTS_SYNID))

        # Hard coded most up to date oncotree version
        oncotreeLink = self.syn.get("syn13890902").externalURL
        # Use the old oncotree link for now
        oncotreeLink = 'http://oncotree.mskcc.org/api/tumorTypes/tree?version=oncotree_2017_06_21'
        oncotreeDict = \
            process_functions.get_oncotree_code_mappings(oncotreeLink)
        mergedClinicalDf['CANCER_TYPE'] = [
            oncotreeDict[code.upper()].get("CANCER_TYPE", float('nan'))
            for code in mergedClinicalDf['ONCOTREE_CODE']]
        mergedClinicalDf['CANCER_TYPE_DETAILED'] = [
            oncotreeDict[code.upper()].get("CANCER_TYPE_DETAILED",
                                           float('nan'))
            for code in mergedClinicalDf['ONCOTREE_CODE']]
        mergedClinicalDf['ONCOTREE_PRIMARY_NODE'] = [
            oncotreeDict[code.upper()].get("ONCOTREE_PRIMARY_NODE",
                                           float('nan'))
            for code in mergedClinicalDf['ONCOTREE_CODE']]
        mergedClinicalDf['ONCOTREE_SECONDARY_NODE'] = [
            oncotreeDict[code.upper()].get("ONCOTREE_SECONDARY_NODE",
                                           float('nan'))
            for code in mergedClinicalDf['ONCOTREE_CODE']]

        mergedClinicalDf.to_csv(
            "%s/data_clinical.txt" % self._SPONSORED_PROJECT,
            index=False, sep="\t")

        if not self.staging:
            process_functions.updateData(
                self.syn,
                "syn17010637",
                finalPatientDf,
                self._SPONSORED_PROJECT,
                filterByColumn="SP",
                toDelete=True)

            patientFileEnt = File(patientPath, parent=self._SP_SYN_ID)
            patientEnt = self.syn.store(
                patientFileEnt,
                used=labelledEnt.id,
                executed=self._GITHUB_REPO)

            process_functions.updateData(
                self.syn,
                "syn17010638",
                finalSampleDf,
                self._SPONSORED_PROJECT,
                filterByColumn="SP",
                toDelete=True)

            sampleFileEnt = File(samplePath, parent=self._SP_SYN_ID)
            sampleEnt = self.syn.store(
                sampleFileEnt,
                used=labelledEnt.id,
                executed=self._GITHUB_REPO)

        treatmentDf = labeledDf[treatmentCols]
        treatmentRows = labeledDf.redcap_repeat_instrument == \
            "Treatment Information Detailed"
        treatmentDf = treatmentDf[treatmentRows]
        finalTimelineDf = self.makeTimeLineDf(treatmentDf,
                                              final_patientdf_datesdays)
        finalTimelineDf.PATIENT_ID = finalTimelineDf.apply(
            lambda x: process_functions.checkGenieId(
                x['PATIENT_ID'], x['CENTER']), axis=1)
        if not self.staging:
            process_functions.updateData(
                self.syn, "syn17011214", finalTimelineDf,
                self._SPONSORED_PROJECT, filterByColumn="SP", toDelete=True)

        # METASTATIC DIAGNOSIS (append to timeline)
        metaDiagnosisDf = self.createMetaDiagnosisDf(finalTimelineDf)
        # Maintain ordering of timeline
        ordering = finalTimelineDf.columns.tolist()
        # Two extra timeline columns from specimen file
        ordering.extend(["SAMPLE_ID", "SAMPLE_NOTES"])
        finalTimelineDf = finalTimelineDf.append(metaDiagnosisDf, sort=False)

        # Create specimen file to append to timeline file too
        specimenDf = self.createSpecimenDf(final_sampledf_datesdays,
                                           final_patientdf_datesdays)
        specimenDf = specimenDf[specimenDf['SAMPLE_ID'].isin(
            genie_clinicalDf['SAMPLE_ID'])]
        # dates = ['START_DATE', 'STOP_DATE', 'LINE_START']
        finalTimelineDf = finalTimelineDf.append(specimenDf, sort=False)
        # No need to convert timeline dates to months
        # finalTimelineDf[dates] = \
        #     finalTimelineDf[dates].applymap(change_days_to_months)
        finalTimelineDf = finalTimelineDf[ordering]
        finalTimelineDf = finalTimelineDf[
            finalTimelineDf['PATIENT_ID'].isin(genie_clinicalDf['PATIENT_ID'])]
        finalTimelineDf['AGENT'][finalTimelineDf['AGENT'].isnull()] = "Unknown"
        timelineText = finalTimelineDf.to_csv(index=False, sep="\t")
        timelineText = replace0(timelineText)
        timeline_path = "%s/data_timeline.txt" % self._SPONSORED_PROJECT
        with open(timeline_path, 'w') as timelineFile:
            timelineFile.write(timelineText)
        if not self.staging:
            fileEnt = File(timeline_path, parent=self._SP_SYN_ID)
            self.syn.store(
                fileEnt, used=labelledEnt.id, executed=self._GITHUB_REPO)

        # Get database to synapse id mapping table so no need to
        # hardcode synapse ids
        databaseToSynIdMapping = \
            self.syn.tableQuery('SELECT * FROM syn10967259')
        databaseToSynIdMappingDf = databaseToSynIdMapping.asDataFrame()

        centerMafFileViewSynId = databaseToSynIdMappingDf['Id'][
            databaseToSynIdMappingDf['Database'] == "centerMafView"][0]
        centerMafSynIds = self.syn.tableQuery(
            "select id from {} where name like '%mutation%'".format(
                centerMafFileViewSynId))
        centerMafSynIdsDf = centerMafSynIds.asDataFrame()
        # This value must be set outside here because the first maf file might
        # Not be part of the centers
        index = 0
        mafpath = "{}/data_mutations_extended.txt".format(
            self._SPONSORED_PROJECT)
        for mafSynId in centerMafSynIdsDf.id:
            mafEnt = self.syn.get(mafSynId, downloadFile=False)
            mafcenter = mafEnt.name.split("_")[3]
            if mafcenter in finalSampleDf['CENTER'].tolist():
                mafEnt = self.syn.get(mafSynId)
                print("running", mafEnt.name)
                with open(mafEnt.path, "r") as mafFile:
                    header = mafFile.readline()
                    headers = header.replace("\n", "").split("\t")
                    if index == 0:
                        with open(mafpath, 'w') as f:
                            f.write(header)
                    index += 1
                    for row in mafFile:
                        rowArray = row.replace("\n", "").split("\t")
                        center = rowArray[headers.index('Center')]
                        newMergedRow = configureMafRow(
                            rowArray, headers, finalSampleDf['SAMPLE_ID'])
                        if newMergedRow is not None:
                            with open(mafpath, 'a') as f:
                                f.write(newMergedRow)
        # No longer need to pulling from non genie db
        fileEnt = File(mafpath, parent=self._SP_SYN_ID)
        if not self.staging:
            self.syn.store(
                fileEnt,
                used=centerMafSynIdsDf.id.tolist(),
                executed=self._GITHUB_REPO)

        CNA_PATH = "%s/data_CNA.txt" % self._SPONSORED_PROJECT
        CNA_CENTER_PATH = self._SPONSORED_PROJECT + "/data_CNA_%s.txt"
        centerCNASynIds = self.syn.tableQuery(
            "select id from {} where name like 'data_CNA%'".format(
                centerMafFileViewSynId))
        centerCNASynIdsDf = centerCNASynIds.asDataFrame()
        # Grab all unique symbols and form cnaTemplate
        allSymbols = set()

        for cnaSynId in centerCNASynIdsDf.id:
            cnaEnt = self.syn.get(cnaSynId)
            with open(cnaEnt.path, "r") as cnaFile:
                # Read first line first to get all the samples
                cnaFile.readline()
                # Get all hugo symbols
                allSymbols = allSymbols.union(
                    set(line.split("\t")[0] for line in cnaFile))
        cnaTemplate = pd.DataFrame({"Hugo_Symbol": list(allSymbols)})
        cnaTemplate.sort_values("Hugo_Symbol", inplace=True)
        cnaTemplate.to_csv(CNA_PATH, sep="\t", index=False)

        withMergedHugoSymbol = pd.Series("Hugo_Symbol")
        withMergedHugoSymbol = \
            withMergedHugoSymbol.append(pd.Series(finalSampleDf['SAMPLE_ID']))
        cnaSamples = []

        for cnaSynId in centerCNASynIdsDf.id:
            cnaEnt = self.syn.get(cnaSynId)
            center = cnaEnt.name.replace(
                "data_CNA_", "").replace(".txt", "")
            print(cnaEnt.path)
            # if center in CENTER_MAPPING_DF.center.tolist():
            centerCNA = pd.read_csv(cnaEnt.path, sep="\t")
            merged = cnaTemplate.merge(
                centerCNA, on="Hugo_Symbol", how="outer")
            merged.sort_values("Hugo_Symbol", inplace=True)

            # This is to remove more samples for the final cna file
            merged = merged[merged.columns[
                merged.columns.isin(withMergedHugoSymbol)]]

            cnaText = process_functions.removePandasDfFloat(merged)
            # Must do this replace twice because \t\t\t ->
            # \tNA\t\t -> \tNA\tNA\t
            cnaText = cnaText.replace(
                "\t\t", "\tNA\t").replace(
                "\t\t", "\tNA\t").replace(
                '\t\n', "\tNA\n")

            with open(CNA_CENTER_PATH % center, "w") as cnaFile:
                cnaFile.write(cnaText)
            cnaSamples.extend(merged.columns[1:].tolist())

            # Join CNA file
            joinCommand = ["join", CNA_PATH, CNA_CENTER_PATH % center]
            output = subprocess.check_output(joinCommand)
            with open(CNA_PATH, "w") as cnaFile:
                cnaFile.write(output.decode("utf-8").replace(" ", "\t"))

        fileEnt = File(CNA_PATH, parent=self._SP_SYN_ID)
        if not self.staging:
            self.syn.store(
                fileEnt,
                used=centerCNASynIdsDf.id.tolist(),
                executed=self._GITHUB_REPO)

        self.createGeneMatrixDf(finalSampleDf, cnaSamples, labelledEnt)

        fusion = self.syn.tableQuery(
            "SELECT * FROM syn7893268 where "
            "TUMOR_SAMPLE_BARCODE in ('{}')".format(
                "','".join(finalSampleDf['SAMPLE_ID'])))
        fusions_df = fusion.asDataFrame()

        if not fusions_df.empty:
            fusions_df = fusions_df.rename(columns={
                'HUGO_SYMBOL': 'Hugo_Symbol',
                'ENTREZ_GENE_ID': 'Entrez_Gene_Id',
                'CENTER': 'Center',
                'TUMOR_SAMPLE_BARCODE': 'Tumor_Sample_Barcode',
                'FUSION': 'Fusion',
                'DNA_SUPPORT': 'DNA_support',
                'RNA_SUPPORT': 'RNA_support',
                'METHOD': 'Method',
                'FRAME': 'Frame',
                'COMMENTS': 'Comments'})
            fusions_df.Entrez_Gene_Id[
                fusions_df.Entrez_Gene_Id == 0] = pd.np.nan
            fusionText = fusions_df.to_csv(sep="\t", index=False)
            fusionText = replace0(fusionText)
            fusion_path = "%s/data_fusions.txt" % self._SPONSORED_PROJECT
            with open(fusion_path, "w") as fusionFile:
                fusionFile.write(fusionText)
            fileEnt = File(fusion_path, parent=self._SP_SYN_ID)
            if not self.staging:
                self.syn.store(
                    fileEnt,
                    used=fusion.tableId,
                    executed=self._GITHUB_REPO)

        seg = self.syn.tableQuery(
            "SELECT ID, CHROM, LOCSTART, LOCEND, NUMMARK, SEGMEAN "
            "FROM syn7893341 where ID in ('{}')".format(
                "','".join(finalSampleDf['SAMPLE_ID'])))
        seg_df = seg.asDataFrame()
        if not seg_df.empty:
            seg_df.rename(columns={
                "CHROM": "chrom",
                "LOCSTART": "loc.start",
                "LOCEND": "loc.end",
                "NUMMARK": "num.mark",
                "SEGMEAN": "seg.mean"}, inplace=True)
            segText = replace0(seg_df.to_csv(sep="\t", index=False))
            segpath = "{}/genie_{}_data_cna_hg19.seg".format(
                self._SPONSORED_PROJECT, self._SPONSORED_PROJECT.lower())
            with open(segpath, 'w') as segFile:
                segFile.write(segText)
            fileEnt = File(segpath, parent=self._SP_SYN_ID)
            if not self.staging:
                self.syn.store(
                    fileEnt, used=seg.tableId, executed=self._GITHUB_REPO)

        # Create case lists
        if not os.path.exists(self._CASE_LIST_PATH):
            os.mkdir(self._CASE_LIST_PATH)
        else:
            caselists = os.listdir(self._CASE_LIST_PATH)
            for caselist in caselists:
                os.remove(os.path.join(self._CASE_LIST_PATH, caselist))

        # Write out cases sequenced so people can tell
        # which samples were sequenced
        create_case_lists.main(
            "%s/data_clinical.txt" % self._SPONSORED_PROJECT,
            "%s/data_gene_matrix.txt" % self._SPONSORED_PROJECT,
            self._CASE_LIST_PATH,
            "genie_{}".format(self._SPONSORED_PROJECT.lower()))

        caseListFiles = os.listdir(self._CASE_LIST_PATH)
        for casePath in caseListFiles:
            casePath = os.path.join(self._CASE_LIST_PATH, casePath)
            fileEnt = File(casePath, parent=self._CASE_LIST_SYN_ID)
            if not self.staging:
                self.syn.store(
                    fileEnt,
                    used=[patientEnt.id, sampleEnt.id],
                    executed=self._GITHUB_REPO)

        seq_assays = "','".join(set(finalSampleDf['SEQ_ASSAY_ID']))
        bed = self.syn.tableQuery("SELECT Hugo_Symbol, SEQ_ASSAY_ID FROM syn8457748 where "
                                  "SEQ_ASSAY_ID in ('{}') and "
                                  "Feature_Type = 'exon' and "
                                  "Hugo_Symbol is not null and "
                                  "includeInPanel is true".format(seq_assays))
        beddf = bed.asDataFrame()
        bed = self.syn.tableQuery("SELECT Hugo_Symbol, SEQ_ASSAY_ID FROM syn11516678 where "
                                  "SEQ_ASSAY_ID in ('{}') and "
                                  "Feature_Type = 'exon' and "
                                  "Hugo_Symbol is not null and "
                                  "includeInPanel is true".format(seq_assays))
        non_genie_beddf = bed.asDataFrame()
        beddf = beddf.append(non_genie_beddf)
        seq_assay_groups = beddf.groupby('SEQ_ASSAY_ID')
        for seq_assay_id, seqdf in seq_assay_groups:
            unique_genes = seqdf.Hugo_Symbol.unique()
            gene_panel_text = ("stable_id: {seq_assay_id}\n"
                               "description: {seq_assay_id}, "
                               "Number of Genes - {num_genes}\n"
                               "gene_list:\t{genelist}".format(
                                   seq_assay_id=seq_assay_id,
                                   num_genes=len(unique_genes),
                                   genelist="\t".join(unique_genes)))
            gene_panel_name = "data_gene_panel_" + seq_assay_id + ".txt"
            gene_panel_path = os.path.join(self._SPONSORED_PROJECT,
                                           gene_panel_name)
            with open(gene_panel_path, "w+") as f:
                f.write(gene_panel_text)
            fileEnt = File(gene_panel_path, parent=self._SP_SYN_ID)
            if not self.staging:
                self.syn.store(
                    fileEnt,
                    executed=self._GITHUB_REPO)

        # Make sure to re download all the metadata files again
        self.reviseMetadataFiles()

        cmd = ['python',
               os.path.join(self.cbioPath,
                            "core/src/main/scripts/importer/validateData.py"),
               "-s", self._SPONSORED_PROJECT, "-n"]
        subprocess.call(cmd)

        # if self.export and self._SPONSORED_PROJECT == "AKT1":
        #   #AKT1 only
        #   files = self.syn.getChildren("syn8363325")
        #   for i in files:
        #       synu.copy(syn, i['id'], "syn8475908", updateExisting=True)
